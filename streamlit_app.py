import streamlit as st
import os
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI

# Configuraci√≥n de p√°gina
st.set_page_config(page_title="Chat con Christian Silva", page_icon="‚ú®")

# Estilos CSS
st.markdown("""
<style>
    .stApp { background-color: #0f172a; color: #e2e8f0; }
    h1 { color: #38bdf8 !important; }
    .stChatMessage { background-color: #1e293b; border: 1px solid #334155; }
    .stTextInput input { color: #0f172a !important; }
</style>
""", unsafe_allow_html=True)

st.title("‚ú® Asistente IA de Christian Silva")
st.write("Potenciado por **Google Gemini**. Preg√∫ntame sobre mi experiencia y proyectos.")

with st.sidebar:
    st.header("Sobre este Chatbot")
    st.info("Esta IA ha le√≠do mi CV y puede responder preguntas sobre mi perfil profesional.")
    st.divider()
    st.write("üìß silvanegrete.ch@gmail.com")
    st.markdown("[Ver c√≥digo fuente en GitHub](https://github.com/christian-devsam/myPortfolioChristianDev)")


try:
    api_key = st.secrets["GOOGLE_API_KEY"]
except FileNotFoundError:
    st.error("‚ö†Ô∏è No se encontr√≥ la API Key. Configura los 'Secrets' en Streamlit Cloud.")
    st.stop()

# --- FUNCIONES ---

def get_pdf_text(pdf_path):
    text = ""
    try:
        pdf_reader = PdfReader(pdf_path)
        for page in pdf_reader.pages:
            text += page.extract_text()
    except FileNotFoundError:
        st.error(f"No se encontr√≥ el archivo {pdf_path}. Aseg√∫rate de subirlo al repo.")
    return text

def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)
    chunks = text_splitter.split_text(text)
    return chunks

def get_vectorstore(text_chunks):
    # Ya no pasamos la api_key como argumento manual, la toma del entorno
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)
    return vectorstore

def get_conversation_chain(vectorstore):
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=api_key, temperature=0.3)
    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory
    )
    return conversation_chain

# --- PROCESAMIENTO ---

if "conversation" not in st.session_state:
    with st.spinner("Inicializando conocimientos de Christian..."):
        try:
            raw_text = get_pdf_text("cv_csilva.pdf")
            text_chunks = get_text_chunks(raw_text)
            vectorstore = get_vectorstore(text_chunks)
            st.session_state.conversation = get_conversation_chain(vectorstore)
            st.session_state.process_complete = True
        except Exception as e:
            st.error(f"Error al iniciar el bot: {e}")

# --- INTERFAZ DE CHAT ---

if "process_complete" in st.session_state:
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    if prompt := st.chat_input("Ej: ¬øQu√© tecnolog√≠as domina Christian?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Analizando respuesta..."):
                try:
                    response = st.session_state.conversation({'question': prompt})
                    ai_response = response['answer']
                    st.write(ai_response)
                    st.session_state.messages.append({"role": "assistant", "content": ai_response})
                except Exception as e:
                    st.error("Ocurri√≥ un error al procesar la respuesta.")